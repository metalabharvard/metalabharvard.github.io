---
name: A Flitting Atlas of the Human Gaze
redirect: https://mlml.io/p/a-flitting-atlas-of-the-human-gaze/
layout: project
type: project 
year: 2021
startdate: 2020
stat: ongoing
featured: false
order: 50
sub: true
sub-name: curatorial-aigents

collaborators: Harvard Art Museums
context: Archives
contact-email: jeffrey@metalab.harvard.edu
contact-person: jeffrey
technologies:


thumbnail_format:



semester: 
school: 


media:
  - medium:
    image: img0.jpg
    id: 00
    stat: featured
  - medium:
    image: img1.jpg
    id: 01
    stat:
  - medium:
    image: img2.jpg
    id: 2
    stat:

    url: http://mlhplayground.org/appc/

press:



bibliography:



tweet-summary: "Using AI-based extraction and analysis, A Flitting Atlas of the Human Gaze allows the visitor to explore the museum through the eyes of the subjects of artworks."



research-questions:




---
<iframe src="https://metalabharvard.github.io/ars-flittingatlasofthegaze/" width="100%" height="800" frameborder="0" title="A Flitting Atlas of the Human Gaze"></iframe><br />

[A Flitting Atlas of the Human Gaze](https://metalabharvard.github.io/ars-flittingatlasofthegaze/)

When the Harvard Art Museum collection looks back at us, which direction does it look? Up, down, left, or right? How deeply or shallowly does it cast its gaze? Do most images peer straight into the visitor’s eyes? What is the orientation of the subject’s head, frontal or rotated? Do particular media or cultural traditions correlate with preferences regarding the directionality of the human gaze? The installation is built upon the AI-based extraction and analysis, fine-tuned via human supervision, of pairs of eyes from the Harvard Art Museum painting, print, sculpture, and coin collections. It allows the visitor, equipped with an input device, to explore the collections from the standpoint of the depicted subject’s gaze direction. A red dot appears where the input device is pointed towards the wall of monitors, establishing a focal point, a point of convergence around which arrays of images are summoned up nine at a time. Opposite the monitors, highlighted zones within the overall cartography of gazes are presented via the gallery’s projection system. For centuries visitors have navigated collections on the basis of culture, chronology, genre, and medium; to those conventional forms of exploration, *A Flitting Atlas of the Human Gaze* adds a new mode based on the distribution of looks across media and time. (Kevin Brewster, Todd Linkner, [Dietmar Offenhuber](https://metalabharvard.github.io/people/dietmar), [Jeffrey Schnapp](https://metalabharvard.github.io/people/jeffrey).)
<iframe src="https://player.vimeo.com/video/409079272" width="100%" height="500" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>
  
[*Curatorial A(i)gents*](https://metalabharvard.github.io/projects/curatorial-aigents/) presents a series of machine-learning-based experiments with museum collections and data developed by members and affiliates of [metaLAB (at) Harvard](https://metalabharvard.github.io/), a creative research group working in the networked arts and humanities.
