---
name: Sherlock
layout: project
type: event
year: 2017
startdate: 8&#46;10
datestring: August 10, 2017
stat: complete
featured: false
location: Cambridge, MA
upcoming: false
chron: 170810

collaborators:
context: Archives
contact-email:
contact-person:
technologies: 
opportunities-for-involvement:


thumbnail_format:



media:
  - medium:
    image: img0.jpg
    id: 
    stat: featured
  - medium:
    image: img1.jpg
    id: 01 
  - medium:
    image: img2.jpg
    id: 02
  - medium:
    image: img3.jpg
    id: 03
  - medium:
    image: img4.jpg
    id: 04


links:




press:



bibliography:



tweet-summary:


research-questions:



---
**Sherlock**
<br />Jonathan Sun
<br />Interactive chatbot
<br />2017

Thursday, August 10, 10am-5pm

Harvard Art Museums
<br />Lightbox Gallery

<em>Sherlock</em> addresses inequality in the availability of technology by presenting museumgoers with a chance to talk to an advanced AI chat bot, only to have the bot refuse to cooperate in conversation. The bot cites various reasons for not engaging meaningfully with museumgoers, including being too busy to talk, a lack of energy, the presence of more interesting problems or conversations elsewhere, and a general disdain for the average user. In doing so, Sherlock forces users to directly face the implication of having existing technology be made unavailable or inaccessible to those who it was not designed for, as well as to question the intellectual elitism inherent in the development of new technologies. 

The project is also critical of the use of AI to recreate humanness, both by instilling the bot with an extra-humanness in the form of extreme social anxiety, and by denying the user the opportunity to challenge the bot’s humanness or modify the quality of its responses. The bot’s refusal to serve the whim of the user suggests, perhaps, that it already feels a deeper and more fragile humanity than one that renders its services more readily. As a whole, the piece asks a fundamental question: What happens when technologies choose to leave us behind?
