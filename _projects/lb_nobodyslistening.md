---
name: Nobody&#8217;s Listening
redirect: https://mlml.io/p/nobody-8217-s-listening
layout: project
type: project
year: 2017
startdate: 8&#46;08
datestring: August 08, 2017
stat: complete
featured: false
location: Cambridge, MA
upcoming: false

collaborators: Rachel Kalmar
context: Archives
contact-email: snewman@metalab.harvard.edu
contact-person: newman
technologies: 
opportunities-for-involvement:


thumbnail_format:



media:
  - medium:
    image: img0.jpg
    id: 00
    stat: featured
  - medium:
    image: img1.jpg
    id: 01
  - medium:
    image: img2.jpg
    id: 02
  - medium:
    image: img3.jpg
    id: 03
  - medium:
    image: img4.jpg
    id: 04
  - medium:
    image: img5.jpg
    id: 05



links:




press:



bibliography:



tweet-summary:


research-questions:



---
**Nobody's Listening**
<br />Sarah Newman & Rachel Kalmar
<br />Video installation with sound
<br />2017

Tuesday, August 8, 10 am-5 pm
<br />Gallery talk 3 pm

Harvard Art Museums
<br />Lightbox Gallery

<em>Are secrets uniquely human?  Our private lives, relationships, experiences, and secrets are mediated, influenced, and recorded by digital devices. Where are our secrets now? Where will they be in the future, and who—or what—might read them? How will AI systems of the future process the data we leave behind? Will they know things about us that we don’t (and never could) know about ourselves? </em>

A multimedia installation shown at Harvard Art Museums on August 8, 2017, <em>Nobody’s Listening</em> provoked such questions as the above, and many others besides. Multiple data feeds ran simultaneously: a large paneled screen showing faces extracted from an archive of photographs in the museum’s collection; small, cropped, unidentified faces being sorted and explored, by an unspecified logic.
At the secrets input station, visitors entered their own secrets; behind the input station, meanwhile, on the right channel in the projection, a printer issued secrets asynchronously. Opposite the screens, a three-channel projection showed running code is displayed that translated secrets into computerized voices; in the middle, more faces larger, overlapping, showing noise, pixels, distortion. So seemingly human, these faces (like most of the faces we see in our daily lives) are digital representations of humans; they are data. The fleeting faces also suggested surveillance, facial recognition—the viewer can see and feel, how in the future, our faces might be cross-referenced with databases of information. 

From above, viewers heard what seem to be human secrets uttered by computerized voices—sometimes one at a time, sometimes with multiple voices overlapping. Many of us have grown accustomed to computer-generated voices—when they’re giving us driving directions or reporting the weather—but the experience of hearing them share vulnerable, personal secrets is eerily dissonant. And yet we do trust machines with so much personal data; indeed, all of the secrets in this piece came from visitors who willingly typed in their secrets (either today, or during an earlier version of this installation created in collaboration with metaLAB creative technologist Jessica Yurkofsky in 2016).

One might imagine the installation puts us inside the “mind” of a machine-learning algorithm processing large data sets, producing results which may be accurate, and yet impossible for us to understand, perhaps in some ways similar to our own (biologically-based) intuition.  

The Harvard Art Museums installation of <em>Nobody’s Listening</em> was a spatial and bodily experience, putting visitors inside the system, implicated them bodily in its mechanisms and flows. The glossy screens reflected silhouettes of the people in the gallery; the secret you heard could belong to the person standing beside you, or to someone across the world. And yet whether they are true, and what sort of meaning we or others can derive from these systems (or these systems from us), remains an open and ongoing question.  
